{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : eval-EXP-20200622-004238\n",
      "06/22 12:42:38 AM gpu device = 0\n",
      "06/22 12:42:38 AM args = Namespace(arch='DARTS', auxiliary=True, auxiliary_weight=0.4, batch_size=48, cutout=True, cutout_length=16, data='../data', drop_path_prob=0.2, epochs=6, gpu=0, grad_clip=5, init_channels=36, layers=20, learning_rate=0.025, model_path='saved_models', momentum=0.9, report_freq=50, save='eval-EXP-20200622-004238', seed=0, weight_decay=0.0003)\n",
      "108 108 36\n",
      "108 144 36\n",
      "144 144 36\n",
      "144 144 36\n",
      "144 144 36\n",
      "144 144 36\n",
      "144 144 72\n",
      "144 288 72\n",
      "288 288 72\n",
      "288 288 72\n",
      "288 288 72\n",
      "288 288 72\n",
      "288 288 72\n",
      "288 288 144\n",
      "288 576 144\n",
      "576 576 144\n",
      "576 576 144\n",
      "576 576 144\n",
      "576 576 144\n",
      "576 576 144\n",
      "06/22 12:42:41 AM param size = 3.349342MB\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "06/22 12:42:42 AM epoch 0 lr 2.332532e-02\n",
      "train.py:129: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n",
      "06/22 12:42:43 AM train 000 3.271232e+00 20.833332 43.750000\n",
      "06/22 12:42:56 AM train 050 3.222215e+00 12.745098 55.841501\n",
      "06/22 12:43:09 AM train 100 3.221625e+00 13.263201 56.765674\n",
      "06/22 12:43:22 AM train 150 3.161661e+00 15.480132 61.189291\n"
     ]
    }
   ],
   "source": [
    "!python train.py --auxiliary --cutout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
